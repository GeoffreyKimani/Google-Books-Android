{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "project (4) - Jeff Version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeoffreyKimani/Google-Books-Android/blob/master/project_(4)_Jeff_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:09:42.763618Z",
          "iopub.execute_input": "2022-04-08T16:09:42.763970Z",
          "iopub.status.idle": "2022-04-08T16:10:06.859312Z",
          "shell.execute_reply.started": "2022-04-08T16:09:42.763890Z",
          "shell.execute_reply": "2022-04-08T16:10:06.858369Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-I4EqiKAJAp",
        "outputId": "f87608df-9b04-4228-befc-e598c36249da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1LIrogRWSL-4CifdzciM6vV8V30JArQG6/view?usp=sharing"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:10:06.862951Z",
          "iopub.execute_input": "2022-04-08T16:10:06.863180Z",
          "iopub.status.idle": "2022-04-08T16:10:30.823810Z",
          "shell.execute_reply.started": "2022-04-08T16:10:06.863153Z",
          "shell.execute_reply": "2022-04-08T16:10:30.822962Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9FeVwd1AJAu",
        "outputId": "3e025681-fc9b-40a6-e9c1-80c0ace8888f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LIrogRWSL-4CifdzciM6vV8V30JArQG6\n",
            "To: /content/phonemes.zip\n",
            "\r  0% 0.00/5.22M [00:00<?, ?B/s]\r100% 5.22M/5.22M [00:00<00:00, 200MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qn ./phonemes.zip\n",
        "!rm -rf '/content/phonemes/validation/pp10/spchdatadir/recording1/Untitled.ipynb'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:10:30.825537Z",
          "iopub.execute_input": "2022-04-08T16:10:30.825990Z",
          "iopub.status.idle": "2022-04-08T16:10:33.066853Z",
          "shell.execute_reply.started": "2022-04-08T16:10:30.825933Z",
          "shell.execute_reply": "2022-04-08T16:10:33.065822Z"
        },
        "trusted": true,
        "id": "fJtLRHEQAJAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummaryX "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:10:33.069307Z",
          "iopub.execute_input": "2022-04-08T16:10:33.069581Z",
          "iopub.status.idle": "2022-04-08T16:10:41.493390Z",
          "shell.execute_reply.started": "2022-04-08T16:10:33.069545Z",
          "shell.execute_reply": "2022-04-08T16:10:41.492535Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlR2cQLwAJAw",
        "outputId": "098feb8a-9b32-40cd-b1e2-d37984a0f680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummaryX in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.21.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.10.0+cu111)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsummaryX) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsummaryX) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchsummaryX) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchsummaryX) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import os.path as osp\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummaryX import summary\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "torch.manual_seed(1)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-04-08T16:10:41.496869Z",
          "iopub.execute_input": "2022-04-08T16:10:41.497096Z",
          "iopub.status.idle": "2022-04-08T16:10:42.873073Z",
          "shell.execute_reply.started": "2022-04-08T16:10:41.497070Z",
          "shell.execute_reply": "2022-04-08T16:10:42.872306Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjWmGKZYAJAw",
        "outputId": "fa510c91-6718-4956-c207-779fb454e29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intents_6 = [\"move\", 'turn', 'approach', 'grab', 'point', 'lift']\n",
        "intents_4 = ['approach', 'grab', 'point', 'lift']\n",
        "intents_2 = ['approach', 'lift']\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:10:42.874397Z",
          "iopub.execute_input": "2022-04-08T16:10:42.874647Z",
          "iopub.status.idle": "2022-04-08T16:10:42.879329Z",
          "shell.execute_reply.started": "2022-04-08T16:10:42.874600Z",
          "shell.execute_reply": "2022-04-08T16:10:42.878673Z"
        },
        "trusted": true,
        "id": "Vs1spSkqAJAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_dir = '/content/phonemes/train/*/spchdatadir/*/*'\n",
        "X_dir_val = '/content/phonemes/validation/*/spchdatadir/*/*'\n",
        "X_dir_test = '/content/phonemes/test/*/spchdatadir/*/*'\n",
        "\n",
        "X_files_train = sorted(glob.glob(X_dir))\n",
        "X_files_val = sorted(glob.glob(X_dir))\n",
        "X_files_test = sorted(glob.glob(X_dir))\n",
        "files = X_files_train\n",
        "files.extend(X_files_val)\n",
        "files.extend(X_files_test)\n",
        "\n",
        "phones = set()\n",
        "\n",
        "for x in files:\n",
        "    f = np.load(x)\n",
        "    phones.update(f)\n",
        "    \n",
        "PHONEMES = list(phones)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:10:42.880763Z",
          "iopub.execute_input": "2022-04-08T16:10:42.881205Z",
          "iopub.status.idle": "2022-04-08T16:10:46.727960Z",
          "shell.execute_reply.started": "2022-04-08T16:10:42.881167Z",
          "shell.execute_reply": "2022-04-08T16:10:46.727098Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Sa1youTAJAy",
        "outputId": "b92dbe24-6f12-4660-f82b-ba355ec7b1bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "uVBkDragQ9v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get number of required records\n",
        "def records(lis, num):\n",
        "    k = []\n",
        "    for i in range(0, len(lis), 15):\n",
        "        k.extend(lis[i:i+num])\n",
        "        \n",
        "    return k\n",
        "\n",
        "def intents_func(intents_lis, X_files, Y_files):\n",
        "    xfiles = []\n",
        "    yfiles = []\n",
        "    for i, file in enumerate(Y_files):         \n",
        "        f = open(file) \n",
        "        intent = f.read()   \n",
        "        if intent in intents_lis:\n",
        "            xfiles.append(X_files[i])\n",
        "            yfiles.append(file)\n",
        "\n",
        "    return xfiles, yfiles, intents_lis\n",
        "\n",
        "def choose_speakers(speakers_lis, xlis, ylis, n=7):\n",
        "    speakers = random.choices(speakers_lis, k=n)\n",
        "    # print(f'{len(speakers)} Speakers: {speakers}')\n",
        "    x_train_files = []\n",
        "    y_train_files = []\n",
        "    for i, file in enumerate(xlis):\n",
        "        dirs = file.split('/')\n",
        "        for speaker in speakers:\n",
        "            if speaker in dirs:\n",
        "                x_train_files.append(file)\n",
        "                y_train_files.append(ylis[i]) \n",
        "    return x_train_files, y_train_files"
      ],
      "metadata": {
        "id": "suFGzbUiQ9UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speakers = ['pp2', 'pp3', 'pp4', 'pp5', 'pp6', 'pp7', 'pp8']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:10:46.729445Z",
          "iopub.execute_input": "2022-04-08T16:10:46.730025Z",
          "iopub.status.idle": "2022-04-08T16:10:46.734782Z",
          "shell.execute_reply.started": "2022-04-08T16:10:46.729981Z",
          "shell.execute_reply": "2022-04-08T16:10:46.733677Z"
        },
        "trusted": true,
        "id": "HrNqSg4mAJA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(PHONEMES)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:10:46.736448Z",
          "iopub.execute_input": "2022-04-08T16:10:46.737290Z",
          "iopub.status.idle": "2022-04-08T16:10:46.750790Z",
          "shell.execute_reply.started": "2022-04-08T16:10:46.737214Z",
          "shell.execute_reply": "2022-04-08T16:10:46.749988Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja4-x4m3AJA1",
        "outputId": "15ae734e-18bb-48c6-ddfc-5611382171ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"The purpose of the project is to convert audio recordings into phonemes and then classify the phonemes into intents.\n",
        "Each sequence of phonemes is mapped to one of 6 intents. The model should be able to read phoneme sequence\n",
        "and output an intent.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jG7PHg2DAJA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The dataset class reads sequnce of phonemes and a correspong intent.\n",
        "The phonemes are mapped into indices using the above PHONEMES list\n",
        "\"\"\"\n",
        "class LibriSamples(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, recs, intents_lst, speakers_num, partition= \"train\"): # You can use partition to specify train or dev\n",
        "        \n",
        "        self.X_dir = '/content/phonemes/' + partition + '/*/spchdatadir/*/*'\n",
        "        self.Y_dir = '/content/phonemes/' + partition + '/*/framedir/*/*'\n",
        "        \n",
        "        self.X_files = sorted(glob.glob(self.X_dir)) # TODO: list files in the mfcc directory\n",
        "        self.Y_files = sorted(glob.glob(self.Y_dir)) # TODO: list files in the transcript directory            \n",
        "        \n",
        "        X_files = records(self.X_files, recs)\n",
        "        Y_files = records(self.Y_files, recs)\n",
        "        \n",
        "        x_files, y_files, self.intents = intents_func(intents_lst, X_files, Y_files)\n",
        "        \n",
        "        if partition == 'train':\n",
        "            self.X_files, self.Y_files = choose_speakers(speakers, x_files, y_files, speakers_num)\n",
        "        else:\n",
        "            self.X_files, self.Y_files = x_files, y_files\n",
        "                \n",
        "        self.PHONEMES = PHONEMES\n",
        "        assert(len(self.X_files) == len(self.Y_files))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_files)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "    \n",
        "        X_path = self.X_files[ind] \n",
        "        Y_path = self.Y_files[ind] #Each file in Y_files has one of the intents in the list above\n",
        "\n",
        "        X = np.load(X_path) #Load numpy files of phonemes corresponding to each recording\n",
        "        X_indices = [PHONEMES.index(xx) for xx in X] #Get index of each phoneme of loaded file\n",
        "        \n",
        "        f = open(Y_path) \n",
        "        r = f.read() #Read each intent\n",
        "        Y_index = self.intents.index(r) #Index of each read intent\n",
        "\n",
        "        f.close()\n",
        "                \n",
        "        return torch.LongTensor(X_indices), Y_index\n",
        "    \n",
        "    def collate_fn(self, batch):\n",
        "\n",
        "        batch_x = [torch.tensor(x) for x,y in batch] \n",
        "        batch_y = [torch.tensor(y) for x,y in batch]\n",
        "        batch_x_pad = pad_sequence(batch_x, batch_first=True, padding_value=0) #Utterances have variable length\n",
        "        lengths_x = [len(x) for x,y in batch] #Store lenghths of all utterances\n",
        "\n",
        "        return batch_x_pad, torch.tensor(batch_y), torch.tensor(lengths_x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:12:42.153519Z",
          "iopub.execute_input": "2022-04-08T16:12:42.154002Z",
          "iopub.status.idle": "2022-04-08T16:12:42.166789Z",
          "shell.execute_reply.started": "2022-04-08T16:12:42.153963Z",
          "shell.execute_reply": "2022-04-08T16:12:42.165542Z"
        },
        "trusted": true,
        "id": "4VJZws7WAJA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_prep(recs, intent_lst, speakers_num):\n",
        "    batch_size = 64\n",
        "\n",
        "    train_data = LibriSamples(recs, intent_lst, speakers_num, 'train')\n",
        "    val_data = LibriSamples(recs, intent_lst, speakers_num, 'validation')\n",
        "    # test_data = LibriSamplesTest(root, 'test_order.csv')\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True, collate_fn=train_data.collate_fn)\n",
        "    val_loader = torch.utils.data.DataLoader(val_data, batch_size, shuffle=False, collate_fn=val_data.collate_fn)\n",
        "\n",
        "    # print(\"Batch size: \", batch_size)\n",
        "    # print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "\n",
        "    for data in val_loader:\n",
        "        x, y, lx = data \n",
        "        # print('Checking shapes')\n",
        "        # print(x.shape, y.shape, lx.shape)\n",
        "        break\n",
        "\n",
        "    return train_loader, val_loader, x, y, lx"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:12:44.582828Z",
          "iopub.execute_input": "2022-04-08T16:12:44.583526Z",
          "iopub.status.idle": "2022-04-08T16:12:44.778604Z",
          "shell.execute_reply.started": "2022-04-08T16:12:44.583486Z",
          "shell.execute_reply": "2022-04-08T16:12:44.777893Z"
        },
        "trusted": true,
        "id": "cZ3i1ITAAJA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test code for checking shapes and return arguments of the train and val loaders\n",
        "# train_loader, val_loader = data_prep() \n",
        "\n",
        "# for data in val_loader:\n",
        "#     x, y, lx = data \n",
        "#     print(x.shape, y.shape, lx.shape)\n",
        "#     break\n",
        "\n",
        "# once\n",
        "train_loader, val_loader, x, y, lx = data_prep(recs=7, intent_lst=intents_4, speakers_num=5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:12:46.620071Z",
          "iopub.execute_input": "2022-04-08T16:12:46.620671Z",
          "iopub.status.idle": "2022-04-08T16:12:46.695061Z",
          "shell.execute_reply.started": "2022-04-08T16:12:46.620613Z",
          "shell.execute_reply": "2022-04-08T16:12:46.692575Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbvFd3w2AJA8",
        "outputId": "e6e668cf-06f5-4c73-a0de-438d92bbe46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ICASSP3CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size=128, hidden_size=512, num_lstm_layers = 2, bidirectional = False, label_size=31):\n",
        "        super().__init__()\n",
        "        self.n_layers = num_lstm_layers \n",
        "        self.hidden = hidden_size\n",
        "        self.bidirectional = bidirectional\n",
        "        \n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "        self.cnn  = nn.Conv1d(embed_size, embed_size, kernel_size=3, padding=1)\n",
        "\n",
        "        self.cnn2 = nn.Conv1d(embed_size, embed_size, kernel_size=5, padding=2)\n",
        "\n",
        "        self.cnn3 = nn.Conv1d(embed_size, embed_size, kernel_size=7, padding=3)\n",
        "\n",
        "        self.batchnorm = nn.BatchNorm1d(3 * embed_size)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size = 3 * embed_size, \n",
        "                            hidden_size = hidden_size, \n",
        "                            num_layers = num_lstm_layers, \n",
        "                            bidirectional = bidirectional,\n",
        "                            dropout = 0.2)\n",
        "\n",
        "        self.linear = nn.Linear(in_features = 2 * hidden_size if bidirectional else hidden_size, \n",
        "                                out_features = label_size)\n",
        "\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        \"\"\"\n",
        "        padded_x: (B,T) padded LongTensor\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        input = self.embed(x)\n",
        "        \n",
        "        batch_size = input.size(0)\n",
        "        input = input.transpose(1,2)    # (B,T,H) -> (B,H,T)\n",
        "\n",
        "        cnn_output = torch.cat([self.cnn(input), self.cnn2(input), self.cnn3(input)], dim=1)\n",
        "\n",
        "        input = F.relu(self.batchnorm(cnn_output))\n",
        "\n",
        "        input = input.transpose(1,2)\n",
        "\n",
        "        pack_tensor = nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=True, enforce_sorted=False)\n",
        "        _, (hn, cn) = self.lstm(pack_tensor)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            h_n = hn.view(self.n_layers, 2, batch_size, self.hidden)\n",
        "            h_n = torch.cat([ h_n[-1, 0,:], h_n[-1,1,:] ], dim = 1)\n",
        "        else:\n",
        "            h_n = hn[-1]\n",
        "        \n",
        "        logits = self.linear(h_n)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:12:51.624055Z",
          "iopub.execute_input": "2022-04-08T16:12:51.624328Z",
          "iopub.status.idle": "2022-04-08T16:12:51.637355Z",
          "shell.execute_reply.started": "2022-04-08T16:12:51.624290Z",
          "shell.execute_reply": "2022-04-08T16:12:51.636654Z"
        },
        "trusted": true,
        "id": "VqhDbwGgAJA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Architecture implemented in the paper\n",
        "# Model Parameters Value\n",
        "# Embedding Size 256\n",
        "# CNN kernel size 3\n",
        "# No. of CNN filters 256\n",
        "# No. of LSTM layers 1 ( or 2)\n",
        "# LSTM hidden size 256\n",
        "# Batch Normalization False\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:13:38.933444Z",
          "iopub.execute_input": "2022-04-08T16:13:38.933728Z",
          "iopub.status.idle": "2022-04-08T16:13:38.938165Z",
          "shell.execute_reply.started": "2022-04-08T16:13:38.933697Z",
          "shell.execute_reply": "2022-04-08T16:13:38.937311Z"
        },
        "trusted": true,
        "id": "dq_XVdBTAJBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ICASSP3CNN(len(PHONEMES)).cuda() \n",
        "summary(model, x.to(device), lx) "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:13:40.773566Z",
          "iopub.execute_input": "2022-04-08T16:13:40.774120Z",
          "iopub.status.idle": "2022-04-08T16:13:49.672777Z",
          "shell.execute_reply.started": "2022-04-08T16:13:40.774078Z",
          "shell.execute_reply": "2022-04-08T16:13:49.672069Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "3nXiXKpOAJBB",
        "outputId": "8629fc41-a9fb-4613-ed89-deede803e182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================================================\n",
            "              Kernel Shape   Output Shape   Params  Mult-Adds\n",
            "Layer                                                        \n",
            "0_embed         [128, 119]  [64, 25, 128]    15232      15232\n",
            "1_cnn        [128, 128, 3]  [64, 128, 25]    49280    1228800\n",
            "2_cnn2       [128, 128, 5]  [64, 128, 25]    82048    2048000\n",
            "3_cnn3       [128, 128, 7]  [64, 128, 25]   114816    2867200\n",
            "4_batchnorm          [384]  [64, 384, 25]      768        384\n",
            "5_lstm                   -     [787, 512]  3940352    3932160\n",
            "6_linear         [512, 31]       [64, 31]    15903      15872\n",
            "-------------------------------------------------------------\n",
            "                        Totals\n",
            "Total params           4218399\n",
            "Trainable params       4218399\n",
            "Non-trainable params         0\n",
            "Mult-Adds             10107648\n",
            "=============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df_sum = df.sum()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Kernel Shape   Output Shape   Params  Mult-Adds\n",
              "Layer                                                        \n",
              "0_embed         [128, 119]  [64, 25, 128]    15232      15232\n",
              "1_cnn        [128, 128, 3]  [64, 128, 25]    49280    1228800\n",
              "2_cnn2       [128, 128, 5]  [64, 128, 25]    82048    2048000\n",
              "3_cnn3       [128, 128, 7]  [64, 128, 25]   114816    2867200\n",
              "4_batchnorm          [384]  [64, 384, 25]      768        384\n",
              "5_lstm                   -     [787, 512]  3940352    3932160\n",
              "6_linear         [512, 31]       [64, 31]    15903      15872"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80cf60aa-58da-4ebe-a532-2e1e6a9270f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_embed</th>\n",
              "      <td>[128, 119]</td>\n",
              "      <td>[64, 25, 128]</td>\n",
              "      <td>15232</td>\n",
              "      <td>15232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_cnn</th>\n",
              "      <td>[128, 128, 3]</td>\n",
              "      <td>[64, 128, 25]</td>\n",
              "      <td>49280</td>\n",
              "      <td>1228800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_cnn2</th>\n",
              "      <td>[128, 128, 5]</td>\n",
              "      <td>[64, 128, 25]</td>\n",
              "      <td>82048</td>\n",
              "      <td>2048000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_cnn3</th>\n",
              "      <td>[128, 128, 7]</td>\n",
              "      <td>[64, 128, 25]</td>\n",
              "      <td>114816</td>\n",
              "      <td>2867200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_batchnorm</th>\n",
              "      <td>[384]</td>\n",
              "      <td>[64, 384, 25]</td>\n",
              "      <td>768</td>\n",
              "      <td>384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_lstm</th>\n",
              "      <td>-</td>\n",
              "      <td>[787, 512]</td>\n",
              "      <td>3940352</td>\n",
              "      <td>3932160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_linear</th>\n",
              "      <td>[512, 31]</td>\n",
              "      <td>[64, 31]</td>\n",
              "      <td>15903</td>\n",
              "      <td>15872</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80cf60aa-58da-4ebe-a532-2e1e6a9270f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80cf60aa-58da-4ebe-a532-2e1e6a9270f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80cf60aa-58da-4ebe-a532-2e1e6a9270f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Network(256, 256, 1, 6).cuda() \n",
        "# summary(model, x.to(device), lx) "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:13:49.674501Z",
          "iopub.execute_input": "2022-04-08T16:13:49.674771Z",
          "iopub.status.idle": "2022-04-08T16:13:49.678217Z",
          "shell.execute_reply.started": "2022-04-08T16:13:49.674734Z",
          "shell.execute_reply": "2022-04-08T16:13:49.677509Z"
        },
        "trusted": true,
        "id": "CqL8R4ooAJBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss() \n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.999, min_lr=0.0005, patience=5, verbose=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:13:49.679585Z",
          "iopub.execute_input": "2022-04-08T16:13:49.680085Z",
          "iopub.status.idle": "2022-04-08T16:13:49.688035Z",
          "shell.execute_reply.started": "2022-04-08T16:13:49.680047Z",
          "shell.execute_reply": "2022-04-08T16:13:49.687274Z"
        },
        "trusted": true,
        "id": "M6wDdXN6AJBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, val_loader,  batch_size=64):  # todo: separation of train & validation. Which data should we train on?\n",
        "    torch.cuda.empty_cache()\n",
        "    epochs = 1000\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        model.train()\n",
        "\n",
        "        batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "\n",
        "        num_correct = 0\n",
        "        total_loss = 0\n",
        "        \n",
        "        for i, _data in enumerate(train_loader):\n",
        "            x, y, input_lengths = _data\n",
        "            data = x.float().to(device)\n",
        "            y = y.long().to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x = x.cuda()\n",
        "            y = y.cuda()\n",
        "\n",
        "            with torch.cuda.amp.autocast():     \n",
        "                outputs = model(x, input_lengths)     \n",
        "                loss = criterion(outputs, y)\n",
        "            \n",
        "            \n",
        "            num_correct += int((torch.argmax(outputs,  axis=1) == y).sum())\n",
        "            total_loss += float(loss)\n",
        "            \n",
        "            ls = torch.argmax(outputs, axis=1)\n",
        "                \n",
        "            batch_bar.set_postfix(\n",
        "                acc=\"{:.04f}%\".format(100 * num_correct / ((i + 1) * batch_size)),\n",
        "                loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "                num_correct=num_correct,\n",
        "                lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "            \n",
        "            scaler.scale(loss).backward() \n",
        "            scaler.step(optimizer) \n",
        "            scaler.update() \n",
        "\n",
        "            batch_bar.update() \n",
        "        batch_bar.close() \n",
        "\n",
        "        print(\"Epoch {}/{}: Train Acc {:.04f}%, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n",
        "            epoch + 1,\n",
        "            epochs,\n",
        "            100 * num_correct / (len(train_loader) * batch_size),\n",
        "            float(total_loss / len(train_loader)),\n",
        "            float(optimizer.param_groups[0]['lr'])))\n",
        "        \n",
        "        model.eval()\n",
        "        batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "        num_correct2 = 0\n",
        "        for i, _data in enumerate(val_loader):\n",
        "            x, y, input_lengths = _data\n",
        "            x = x.cuda()\n",
        "            y = y.cuda()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(x, input_lengths)\n",
        "\n",
        "            num_correct2 += int((torch.argmax(outputs,  axis=1) == y).sum())\n",
        "            batch_bar.set_postfix(acc=\"{:.04f}%\".format(100 * num_correct2 / ((i + 1) * batch_size)))\n",
        "\n",
        "            batch_bar.update()\n",
        "        \n",
        "        batch_bar.close()\n",
        "        validation_score = 100 * num_correct2 / ((len(val_loader) * batch_size))\n",
        "        print(\"Validation: {:.04f}%\".format(validation_score))\n",
        "\n",
        "        return validation_score"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-08T16:13:55.063472Z",
          "iopub.execute_input": "2022-04-08T16:13:55.063992Z"
        },
        "trusted": true,
        "id": "I03os2nQAJBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_tst():\n",
        "    eps = 10\n",
        "    for i in range(eps):\n",
        "        print(f'Hello {i}')\n",
        "\n",
        "break "
      ],
      "metadata": {
        "id": "-pCNMu9jEijM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tests"
      ],
      "metadata": {
        "id": "GsBoEEfTWncy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# grid search\n",
        "params = {\n",
        "    'intents': zip([\"Two\", \"Four\", \"Six\"],[intents_2, intents_4, intents_6]),\n",
        "    'speakers': range(1, 8),\n",
        "    'recordings': range(5, 12)\n",
        "}\n",
        "\n",
        "intent_scores = {}\n",
        "for name, intent in params['intents']:\n",
        "    \n",
        "    k_scores = {}\n",
        "    for k in params['recordings']:\n",
        "    \n",
        "        s_scores = {}\n",
        "        for s in params['speakers']:\n",
        "            print(f'i: {name} k: {k} s: {s} phones: {len(PHONEMES)}')\n",
        "            # num = random.randint(0, 100) # todo remove\n",
        "\n",
        "            train_loader, val_loader, x, y, lx = data_prep(recs=k, intent_lst=intent, speakers_num=s)\n",
        "            val_score = train(train_loader, val_loader)\n",
        "\n",
        "            s_scores.update({s: val_score})\n",
        "\n",
        "        k_scores.update({k: s_scores})\n",
        "    intent_scores.update({name: k_scores})"
      ],
      "metadata": {
        "id": "87bq0_A5WpUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(PHONEMES)"
      ],
      "metadata": {
        "id": "pv5E-qNS1WTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# intent_scores"
      ],
      "metadata": {
        "id": "fm3QhPMonZc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = []\n",
        "for k, v in intent_scores.items():\n",
        "    # print(k)\n",
        "    df.append((k, pd.DataFrame(v)))\n",
        "\n",
        "display(df[0][0])\n",
        "df[0][1]"
      ],
      "metadata": {
        "id": "QnBYJo1GgESi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ph = np.load(sorted(glob.glob('/content/phonemes/train/*/spchdatadir/*/*'))[0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "i1UxjAK8AJBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = [PHONEMES.index(yy) for yy in ph]"
      ],
      "metadata": {
        "trusted": true,
        "id": "r5iqe-UOAJBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "trusted": true,
        "id": "iGr88Us6AJBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embeds(torch.LongTensor(label))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-31T21:05:24.562297Z",
          "iopub.status.idle": "2022-03-31T21:05:24.562934Z",
          "shell.execute_reply.started": "2022-03-31T21:05:24.562656Z",
          "shell.execute_reply": "2022-03-31T21:05:24.56269Z"
        },
        "trusted": true,
        "id": "-uCRplUsAJBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fk = sorted(glob.glob('/content/phonemes/validation/*/framedir/*/*'))\n",
        "len(fk)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-31T21:05:24.564134Z",
          "iopub.status.idle": "2022-03-31T21:05:24.564696Z",
          "shell.execute_reply.started": "2022-03-31T21:05:24.564446Z",
          "shell.execute_reply": "2022-03-31T21:05:24.56447Z"
        },
        "trusted": true,
        "id": "bKE88lxiAJBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fl = sorted(glob.glob('/content/phonemes/train/*/spchdatadir/*/*'))\n",
        "len(fl)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-31T21:05:24.565832Z",
          "iopub.status.idle": "2022-03-31T21:05:24.566469Z",
          "shell.execute_reply.started": "2022-03-31T21:05:24.566202Z",
          "shell.execute_reply": "2022-03-31T21:05:24.56623Z"
        },
        "trusted": true,
        "id": "aLXMNv_gAJBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf '/content/phonemes/validation/pp10/spchdatadir/recording1/Untitled.ipynb'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-31T21:05:24.567615Z",
          "iopub.status.idle": "2022-03-31T21:05:24.568176Z",
          "shell.execute_reply.started": "2022-03-31T21:05:24.567932Z",
          "shell.execute_reply": "2022-03-31T21:05:24.567965Z"
        },
        "trusted": true,
        "id": "CoeanmA-AJBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fl"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-31T21:05:24.569244Z",
          "iopub.status.idle": "2022-03-31T21:05:24.569805Z",
          "shell.execute_reply.started": "2022-03-31T21:05:24.569559Z",
          "shell.execute_reply": "2022-03-31T21:05:24.569597Z"
        },
        "trusted": true,
        "id": "JihjIN9qAJBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(fl)\n",
        "r = f.read()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-31T21:05:24.570865Z",
          "iopub.status.idle": "2022-03-31T21:05:24.571419Z",
          "shell.execute_reply.started": "2022-03-31T21:05:24.571184Z",
          "shell.execute_reply": "2022-03-31T21:05:24.571208Z"
        },
        "trusted": true,
        "id": "nrWYUSL6AJBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = f.read()\n",
        "f.close()\n",
        "r"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-31T21:05:24.572488Z",
          "iopub.status.idle": "2022-03-31T21:05:24.573104Z",
          "shell.execute_reply.started": "2022-03-31T21:05:24.572858Z",
          "shell.execute_reply": "2022-03-31T21:05:24.572883Z"
        },
        "trusted": true,
        "id": "hD0Zh9diAJBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents.index(r)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-31T21:05:24.575572Z",
          "iopub.status.idle": "2022-03-31T21:05:24.576144Z",
          "shell.execute_reply.started": "2022-03-31T21:05:24.5759Z",
          "shell.execute_reply": "2022-03-31T21:05:24.575925Z"
        },
        "trusted": true,
        "id": "D1XdMVLtAJBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bWi5W2AKWiW3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}